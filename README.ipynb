{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b0133f",
   "metadata": {},
   "source": [
    "# Build our Docker image \"my-custom-sagemaker-training-image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c907ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [sagemaker-training internal] load build definition from Dockerfile.train\n",
      "#1 transferring dockerfile: 38B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [sagemaker-training internal] load .dockerignore\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [sagemaker-training auth] sharing credentials for 683313688378.dkr.ecr.us-east-1.amazonaws.com\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [sagemaker-training internal] load metadata for 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "#4 DONE 0.1s\n",
      "\n",
      "#5 [sagemaker-training 1/3] FROM 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3@sha256:9b43ef4706faae38d10bdff012a0d1b35ed9c5b3aac9e60c960170f10d29fa51\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [sagemaker-training internal] load build context\n",
      "#6 transferring context: 3.23kB done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [sagemaker-training 2/3] ADD ./src/train /opt/ml/code/\n",
      "#7 CACHED\n",
      "\n",
      "#8 [sagemaker-training 3/3] RUN pip install -r /opt/ml/code/requirements.txt\n",
      "#8 CACHED\n",
      "\n",
      "#9 [sagemaker-training] exporting to image\n",
      "#9 exporting layers done\n",
      "#9 writing image sha256:83881e1351fea4880dc91bd78d8046d94a7bb39ebb1bf3ea32e9f0ac240d9d2c done\n",
      "#9 naming to docker.io/library/my-custom-sagemaker-training-image done\n",
      "#9 DONE 0.0s\n",
      "DOCKER BUILD TERMINATED AT Thu Nov 30 20:42:37 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
    "docker-compose build sagemaker-training\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a3c8b",
   "metadata": {},
   "source": [
    "# Using SageMaker Python SDK we can test our Docker image -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software Development Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a591f68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: my-custom-sagemaker-training-image-2023-11-30-20-42-59-821\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-ldtvw:\n",
      "    command: train\n",
      "    container_name: w2a4yp11p3-algo-1-ldtvw\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: my-custom-sagemaker-training-image\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-ldtvw\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpn0ho9apt/algo-1-ldtvw/input:/opt/ml/input\n",
      "    - /tmp/tmpn0ho9apt/algo-1-ldtvw/output:/opt/ml/output\n",
      "    - /tmp/tmpn0ho9apt/algo-1-ldtvw/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpn0ho9apt/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/input:/opt/ml/input/data/training\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpn0ho9apt/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ESTIMATOR FIT STARTED\n",
      "time=\"2023-11-30T20:42:59Z\" level=warning msg=\"a network with name sagemaker-local exists but was not created for project \\\"tmpn0ho9apt\\\".\\nSet `external: true` to use an existing network\"\n",
      " Container w2a4yp11p3-algo-1-ldtvw  Creating\n",
      " Container w2a4yp11p3-algo-1-ldtvw  Created\n",
      "Attaching to w2a4yp11p3-algo-1-ldtvw\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:01,201 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:01,204 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:01,214 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:01,215 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "w2a4yp11p3-algo-1-ldtvw  | /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "w2a4yp11p3-algo-1-ldtvw  | Requirement already satisfied: pandas==1.1.5 in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.5)\n",
      "w2a4yp11p3-algo-1-ldtvw  | Requirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\n",
      "w2a4yp11p3-algo-1-ldtvw  | Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "w2a4yp11p3-algo-1-ldtvw  | Requirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.24.1)\n",
      "w2a4yp11p3-algo-1-ldtvw  | Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:02,132 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:02,147 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:02,161 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:02,172 sagemaker-training-toolkit INFO     Invoking user script\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | Training Env:\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | {\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"additional_framework_parameters\": {},\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"channel_input_dirs\": {\n",
      "w2a4yp11p3-algo-1-ldtvw  |         \"training\": \"/opt/ml/input/data/training\"\n",
      "w2a4yp11p3-algo-1-ldtvw  |     },\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"current_host\": \"algo-1-ldtvw\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"hosts\": [\n",
      "w2a4yp11p3-algo-1-ldtvw  |         \"algo-1-ldtvw\"\n",
      "w2a4yp11p3-algo-1-ldtvw  |     ],\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"hyperparameters\": {\n",
      "w2a4yp11p3-algo-1-ldtvw  |         \"epochs\": 1\n",
      "w2a4yp11p3-algo-1-ldtvw  |     },\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"input_data_config\": {\n",
      "w2a4yp11p3-algo-1-ldtvw  |         \"training\": {\n",
      "w2a4yp11p3-algo-1-ldtvw  |             \"TrainingInputMode\": \"File\"\n",
      "w2a4yp11p3-algo-1-ldtvw  |         }\n",
      "w2a4yp11p3-algo-1-ldtvw  |     },\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"input_dir\": \"/opt/ml/input\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"is_master\": true,\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"job_name\": \"my-custom-sagemaker-training-image-2023-11-30-20-42-59-821\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"log_level\": 20,\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"master_hostname\": \"algo-1-ldtvw\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"model_dir\": \"/opt/ml/model\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"module_dir\": \"/opt/ml/code\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"module_name\": \"my-custom-training-script\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"network_interface_name\": \"eth0\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"num_cpus\": 4,\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"num_gpus\": 0,\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"output_dir\": \"/opt/ml/output\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"resource_config\": {\n",
      "w2a4yp11p3-algo-1-ldtvw  |         \"current_host\": \"algo-1-ldtvw\",\n",
      "w2a4yp11p3-algo-1-ldtvw  |         \"hosts\": [\n",
      "w2a4yp11p3-algo-1-ldtvw  |             \"algo-1-ldtvw\"\n",
      "w2a4yp11p3-algo-1-ldtvw  |         ]\n",
      "w2a4yp11p3-algo-1-ldtvw  |     },\n",
      "w2a4yp11p3-algo-1-ldtvw  |     \"user_entry_point\": \"my-custom-training-script.py\"\n",
      "w2a4yp11p3-algo-1-ldtvw  | }\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | Environment variables:\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_HOSTS=[\"algo-1-ldtvw\"]\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_HPS={\"epochs\":1}\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_USER_ENTRY_POINT=my-custom-training-script.py\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_FRAMEWORK_PARAMS={}\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ldtvw\",\"hosts\":[\"algo-1-ldtvw\"]}\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_CHANNELS=[\"training\"]\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_CURRENT_HOST=algo-1-ldtvw\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_MODULE_NAME=my-custom-training-script\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_LOG_LEVEL=20\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_INPUT_DIR=/opt/ml/input\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_NUM_CPUS=4\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_NUM_GPUS=0\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_MODEL_DIR=/opt/ml/model\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_MODULE_DIR=/opt/ml/code\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-ldtvw\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-ldtvw\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"my-custom-sagemaker-training-image-2023-11-30-20-42-59-821\",\"log_level\":20,\"master_hostname\":\"algo-1-ldtvw\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ldtvw\",\"hosts\":[\"algo-1-ldtvw\"]},\"user_entry_point\":\"my-custom-training-script.py\"}\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_USER_ARGS=[\"--epochs\",\"1\"]\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "w2a4yp11p3-algo-1-ldtvw  | SM_HP_EPOCHS=1\n",
      "w2a4yp11p3-algo-1-ldtvw  | PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | Invoking script with the following command:\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | /miniconda3/bin/python my-custom-training-script.py --epochs 1\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | DEBUG:root:Loading the dataset...\n",
      "w2a4yp11p3-algo-1-ldtvw  | ERROR:root:Error occurred: [Errno 2] No such file or directory: '2023-24-UFS14-ML_mene/data/input/housing.csv'\n",
      "w2a4yp11p3-algo-1-ldtvw  | ERROR:root:Traceback (most recent call last):\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"my-custom-training-script.py\", line 15, in <module>\n",
      "w2a4yp11p3-algo-1-ldtvw  |     df = pd.read_csv('2023-24-UFS14-ML_mene/data/input/housing.csv')\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
      "w2a4yp11p3-algo-1-ldtvw  |     return _read(filepath_or_buffer, kwds)\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 454, in _read\n",
      "w2a4yp11p3-algo-1-ldtvw  |     parser = TextFileReader(fp_or_buf, **kwds)\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 948, in __init__\n",
      "w2a4yp11p3-algo-1-ldtvw  |     self._make_engine(self.engine)\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1180, in _make_engine\n",
      "w2a4yp11p3-algo-1-ldtvw  |     self._engine = CParserWrapper(self.f, **self.options)\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2010, in __init__\n",
      "w2a4yp11p3-algo-1-ldtvw  |     self._reader = parsers.TextReader(src, **kwds)\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
      "w2a4yp11p3-algo-1-ldtvw  |   File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "w2a4yp11p3-algo-1-ldtvw  | FileNotFoundError: [Errno 2] No such file or directory: '2023-24-UFS14-ML_mene/data/input/housing.csv'\n",
      "w2a4yp11p3-algo-1-ldtvw  | \n",
      "w2a4yp11p3-algo-1-ldtvw  | 2023-11-30 20:43:03,300 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmpn0ho9apt/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpn0ho9apt/algo-1-ldtvw/output/success -> /tmp/tmpn0ho9apt/artifacts/output\n",
      "INFO:root:copying /tmp/tmpn0ho9apt/compressed_artifacts/model.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/output\n",
      "INFO:root:copying /tmp/tmpn0ho9apt/compressed_artifacts/output.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2a4yp11p3-algo-1-ldtvw exited with code 0\n",
      "Aborting on container exit...\n",
      " Container w2a4yp11p3-algo-1-ldtvw  Stopping\n",
      " Container w2a4yp11p3-algo-1-ldtvw  Stopped\n",
      "===== Job Complete =====\n",
      "##### ESTIMATOR FIT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "hyperparameters={'epochs': 1}\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='my-custom-sagemaker-training-image',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path='file://{}/data/output'.format(os.getcwd())\n",
    ")\n",
    "\n",
    "print('##### ESTIMATOR FIT STARTED')\n",
    "estimator.fit('file://{}/data/input/housing.csv'.format(os.getcwd()))\n",
    "print('##### ESTIMATOR FIT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844d31f",
   "metadata": {},
   "source": [
    "# NB: if you encountered an error related to `network sagemaker-local was found but has incorrect label com.docker.compose.network set to \"\"` run the following command in the terminal and retry the above cell\n",
    "`docker network prune --force`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Extracting local training archives to see the results\n",
    "\n",
    "tar -xvf $PWD/data/output/model.tar.gz -C $PWD/data/output/model\n",
    "tar -xvf $PWD/data/output/output.tar.gz -C $PWD/data/output\n",
    "\n",
    "echo \"Check the above files in the $PWD/data/output directory!!!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45be40",
   "metadata": {},
   "source": [
    "# As our image works as expected we can build it again with the right ECR image URI and push it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-training-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} -f Dockerfile.train .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8110e73",
   "metadata": {},
   "source": [
    "NB: if the last command \"docker push\" remain pending check README.md \"AWS ECR IAM policies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb0f2a",
   "metadata": {},
   "source": [
    "Before executing a training job on SageMaker we need to move our input data to AWS S3.\n",
    "Obv. we also need an S3 bucket first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72405c",
   "metadata": {},
   "source": [
    "# Create an S3 bucket using AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a random AWS S3 bucket name sharing the name between sh/bash and other Python cells.\n",
    "# # NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "# import random\n",
    "\n",
    "# bucket_name='a-random-bucket-name-pino'\n",
    "\n",
    "# %set_env AWS_S3_BUCKET_NAME=$bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sh\n",
    "\n",
    "# # NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "# aws s3api create-bucket --bucket $AWS_S3_BUCKET_NAME --region $(aws configure get region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8be6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "\n",
    "url = 'file://{}/data/input/housing.csv'.format(os.getcwd())\n",
    "df_demo = pd.read_csv(url,',')\n",
    "\n",
    "prefix='demo'\n",
    "train_file='demo_train.csv'\n",
    "test_file='demo_test.csv'\n",
    "validate_file='demo_validate.csv'\n",
    "whole_file='demo.csv'\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "train, test_and_validate = train_test_split(df_demo, \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=42, \n",
    "                                            stratify=df_demo['median_house_value'])\n",
    "\n",
    "test, validate = train_test_split(test_and_validate, \n",
    "                                  test_size=0.5, \n",
    "                                  random_state=42, \n",
    "                                  stratify=test_and_validate['median_house_value'])\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket_name).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket_name, prefix, train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket_name, prefix, validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf3ebb0",
   "metadata": {},
   "source": [
    "As we have pushed our Docker image to ECR and uploaded our input data to AWS S3 we can use it with a training job on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "image_name='my-custom-sagemaker-training-image'\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)\n",
    "print('###### ecr_image is: {}'.format(ecr_image))\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=get_execution_role(),\n",
    "    base_job_name='custom-docker-image-for-training',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    output_path='s3://{}'.format(bucket_name)\n",
    ")\n",
    "\n",
    "# start training\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2cc78",
   "metadata": {},
   "source": [
    "Before deploy our model we need to test it locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b535d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
    "\n",
    "docker-compose build sagemaker-inference\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4178013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# create our sagemaker-inference container\n",
    "docker-compose create sagemaker-inference\n",
    "\n",
    "# create our sagemaker-inference container\n",
    "docker-compose start sagemaker-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# read logs of our sagemaker-inference container\n",
    "cat $PWD/data/output-compose/data/logs-inference.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9bb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "echo \"GET /ping BELOW\"\n",
    "# call our ping endpoint\n",
    "curl localhost:8080/ping\n",
    "echo \"\"\n",
    "\n",
    "echo \"POST /invocations BELOW\"\n",
    "# call our inference endpoint\n",
    "curl -X post localhost:8080/invocations\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# docker-compose stop sagemaker-inference\n",
    "# docker-compose rm sagemaker-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11955158",
   "metadata": {},
   "source": [
    "# Let's go deploy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8871f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-inference-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} -f Dockerfile.inference .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba46b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "aws_region = my_session.region_name\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model_name = 'training-2023-11-23-18-45-31-074'\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': '590460693729.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-inference-image:latest',\n",
    "        'ModelDataUrl': 's3://a-random-bucket-name-751357/custom-docker-image-for-training-2023-11-23-18-45-31-074/output/model.tar.gz',\n",
    "    })\n",
    "\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'my-first-custom-endpoint-config-name'\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'my-first-custom-endpoint'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76dc374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Let's try our inference!!!\n",
    "aws sagemaker-runtime invoke-endpoint --endpoint-name 'my-first-custom-endpoint' --body '{}' inference-response.json\n",
    "\n",
    "cat inference-response.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
