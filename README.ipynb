{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba7e9f2",
   "metadata": {},
   "source": [
    "# Build our Docker image \"my-custom-sagemaker-training-image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae7fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [sagemaker-training internal] load build definition from Dockerfile.train\n",
      "#1 transferring dockerfile: 650B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [sagemaker-training internal] load .dockerignore\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [sagemaker-training internal] load metadata for 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [sagemaker-training internal] load build context\n",
      "#4 transferring context: 4.97kB done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [sagemaker-training 1/3] FROM 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "#5 CACHED\n",
      "\n",
      "#6 [sagemaker-training 2/3] ADD ./src/train /opt/ml/code/\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [sagemaker-training 3/3] RUN pip install -r /opt/ml/code/requirements.txt\n",
      "#7 1.136 Collecting pandas==1.1.5 (from -r /opt/ml/code/requirements.txt (line 1))\n",
      "#7 1.169   Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
      "#7 1.294      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 76.8 MB/s eta 0:00:00\n",
      "#7 1.343 Requirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (2.8.1)\n",
      "#7 1.344 Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (2023.3.post1)\n",
      "#7 1.345 Requirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (1.24.1)\n",
      "#7 1.349 Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (1.15.0)\n",
      "#7 1.762 Installing collected packages: pandas\n",
      "#7 1.762   Attempting uninstall: pandas\n",
      "#7 1.763     Found existing installation: pandas 1.1.3\n",
      "#7 1.893     Uninstalling pandas-1.1.3:\n",
      "#7 2.306       Successfully uninstalled pandas-1.1.3\n",
      "#7 5.597 ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "#7 5.597 sagemaker-sklearn-container 2.0 requires pandas==1.1.3, but you have pandas 1.1.5 which is incompatible.\n",
      "#7 5.597 Successfully installed pandas-1.1.5\n",
      "#7 DONE 5.9s\n",
      "\n",
      "#8 [sagemaker-training] exporting to image\n",
      "#8 exporting layers\n",
      "#8 exporting layers 0.5s done\n",
      "#8 writing image sha256:683f6cd4de2729dcaac50d29b230e9bcd9f7f31336171d323cafa998d781a323 done\n",
      "#8 naming to docker.io/library/my-custom-sagemaker-training-image done\n",
      "#8 DONE 0.5s\n",
      "DOCKER BUILD TERMINATED AT Thu Nov 30 21:26:09 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
    "docker-compose build sagemaker-training\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75553397",
   "metadata": {},
   "source": [
    "# Using SageMaker Python SDK we can test our Docker image -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software Development Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25620d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: my-custom-sagemaker-training-image-2023-11-30-21-26-14-246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ESTIMATOR FIT STARTED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-xonrr:\n",
      "    command: train\n",
      "    container_name: ta618hs3wx-algo-1-xonrr\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: my-custom-sagemaker-training-image\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-xonrr\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp69995cb0/algo-1-xonrr/output:/opt/ml/output\n",
      "    - /tmp/tmp69995cb0/algo-1-xonrr/input:/opt/ml/input\n",
      "    - /tmp/tmp69995cb0/algo-1-xonrr/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmp69995cb0/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/input:/opt/ml/input/data/training\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmp69995cb0/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time=\"2023-11-30T21:26:14Z\" level=warning msg=\"a network with name sagemaker-local exists but was not created for project \\\"tmp69995cb0\\\".\\nSet `external: true` to use an existing network\"\n",
      " Container ta618hs3wx-algo-1-xonrr  Creating\n",
      " Container ta618hs3wx-algo-1-xonrr  Created\n",
      "Attaching to ta618hs3wx-algo-1-xonrr\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:15,580 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:15,583 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:15,593 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:15,594 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "ta618hs3wx-algo-1-xonrr  | /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "ta618hs3wx-algo-1-xonrr  | Requirement already satisfied: pandas==1.1.5 in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.5)\n",
      "ta618hs3wx-algo-1-xonrr  | Requirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\n",
      "ta618hs3wx-algo-1-xonrr  | Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "ta618hs3wx-algo-1-xonrr  | Requirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.24.1)\n",
      "ta618hs3wx-algo-1-xonrr  | Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:16,514 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:16,529 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:16,542 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:16,552 sagemaker-training-toolkit INFO     Invoking user script\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | Training Env:\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | {\n",
      "ta618hs3wx-algo-1-xonrr  |     \"additional_framework_parameters\": {},\n",
      "ta618hs3wx-algo-1-xonrr  |     \"channel_input_dirs\": {\n",
      "ta618hs3wx-algo-1-xonrr  |         \"training\": \"/opt/ml/input/data/training\"\n",
      "ta618hs3wx-algo-1-xonrr  |     },\n",
      "ta618hs3wx-algo-1-xonrr  |     \"current_host\": \"algo-1-xonrr\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"hosts\": [\n",
      "ta618hs3wx-algo-1-xonrr  |         \"algo-1-xonrr\"\n",
      "ta618hs3wx-algo-1-xonrr  |     ],\n",
      "ta618hs3wx-algo-1-xonrr  |     \"hyperparameters\": {\n",
      "ta618hs3wx-algo-1-xonrr  |         \"epochs\": 1\n",
      "ta618hs3wx-algo-1-xonrr  |     },\n",
      "ta618hs3wx-algo-1-xonrr  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"input_data_config\": {\n",
      "ta618hs3wx-algo-1-xonrr  |         \"training\": {\n",
      "ta618hs3wx-algo-1-xonrr  |             \"TrainingInputMode\": \"File\"\n",
      "ta618hs3wx-algo-1-xonrr  |         }\n",
      "ta618hs3wx-algo-1-xonrr  |     },\n",
      "ta618hs3wx-algo-1-xonrr  |     \"input_dir\": \"/opt/ml/input\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"is_master\": true,\n",
      "ta618hs3wx-algo-1-xonrr  |     \"job_name\": \"my-custom-sagemaker-training-image-2023-11-30-21-26-14-246\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"log_level\": 20,\n",
      "ta618hs3wx-algo-1-xonrr  |     \"master_hostname\": \"algo-1-xonrr\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"model_dir\": \"/opt/ml/model\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"module_dir\": \"/opt/ml/code\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"module_name\": \"my-custom-training-script\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"network_interface_name\": \"eth0\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"num_cpus\": 4,\n",
      "ta618hs3wx-algo-1-xonrr  |     \"num_gpus\": 0,\n",
      "ta618hs3wx-algo-1-xonrr  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"output_dir\": \"/opt/ml/output\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "ta618hs3wx-algo-1-xonrr  |     \"resource_config\": {\n",
      "ta618hs3wx-algo-1-xonrr  |         \"current_host\": \"algo-1-xonrr\",\n",
      "ta618hs3wx-algo-1-xonrr  |         \"hosts\": [\n",
      "ta618hs3wx-algo-1-xonrr  |             \"algo-1-xonrr\"\n",
      "ta618hs3wx-algo-1-xonrr  |         ]\n",
      "ta618hs3wx-algo-1-xonrr  |     },\n",
      "ta618hs3wx-algo-1-xonrr  |     \"user_entry_point\": \"my-custom-training-script.py\"\n",
      "ta618hs3wx-algo-1-xonrr  | }\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | Environment variables:\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | SM_HOSTS=[\"algo-1-xonrr\"]\n",
      "ta618hs3wx-algo-1-xonrr  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "ta618hs3wx-algo-1-xonrr  | SM_HPS={\"epochs\":1}\n",
      "ta618hs3wx-algo-1-xonrr  | SM_USER_ENTRY_POINT=my-custom-training-script.py\n",
      "ta618hs3wx-algo-1-xonrr  | SM_FRAMEWORK_PARAMS={}\n",
      "ta618hs3wx-algo-1-xonrr  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-xonrr\",\"hosts\":[\"algo-1-xonrr\"]}\n",
      "ta618hs3wx-algo-1-xonrr  | SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "ta618hs3wx-algo-1-xonrr  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "ta618hs3wx-algo-1-xonrr  | SM_CHANNELS=[\"training\"]\n",
      "ta618hs3wx-algo-1-xonrr  | SM_CURRENT_HOST=algo-1-xonrr\n",
      "ta618hs3wx-algo-1-xonrr  | SM_MODULE_NAME=my-custom-training-script\n",
      "ta618hs3wx-algo-1-xonrr  | SM_LOG_LEVEL=20\n",
      "ta618hs3wx-algo-1-xonrr  | SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "ta618hs3wx-algo-1-xonrr  | SM_INPUT_DIR=/opt/ml/input\n",
      "ta618hs3wx-algo-1-xonrr  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "ta618hs3wx-algo-1-xonrr  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "ta618hs3wx-algo-1-xonrr  | SM_NUM_CPUS=4\n",
      "ta618hs3wx-algo-1-xonrr  | SM_NUM_GPUS=0\n",
      "ta618hs3wx-algo-1-xonrr  | SM_MODEL_DIR=/opt/ml/model\n",
      "ta618hs3wx-algo-1-xonrr  | SM_MODULE_DIR=/opt/ml/code\n",
      "ta618hs3wx-algo-1-xonrr  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-xonrr\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-xonrr\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"my-custom-sagemaker-training-image-2023-11-30-21-26-14-246\",\"log_level\":20,\"master_hostname\":\"algo-1-xonrr\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-xonrr\",\"hosts\":[\"algo-1-xonrr\"]},\"user_entry_point\":\"my-custom-training-script.py\"}\n",
      "ta618hs3wx-algo-1-xonrr  | SM_USER_ARGS=[\"--epochs\",\"1\"]\n",
      "ta618hs3wx-algo-1-xonrr  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "ta618hs3wx-algo-1-xonrr  | SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "ta618hs3wx-algo-1-xonrr  | SM_HP_EPOCHS=1\n",
      "ta618hs3wx-algo-1-xonrr  | PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | Invoking script with the following command:\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | /miniconda3/bin/python my-custom-training-script.py --epochs 1\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | DEBUG:root:Loading the dataset...\n",
      "ta618hs3wx-algo-1-xonrr  | ERROR:root:Error occurred: [Errno 2] No such file or directory: '2023-24-UFS14-ML_mene/data/input/housing.csv'\n",
      "ta618hs3wx-algo-1-xonrr  | ERROR:root:Traceback (most recent call last):\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"my-custom-training-script.py\", line 18, in <module>\n",
      "ta618hs3wx-algo-1-xonrr  |     df = pd.read_csv('2023-24-UFS14-ML_mene/data/input/housing.csv')\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
      "ta618hs3wx-algo-1-xonrr  |     return _read(filepath_or_buffer, kwds)\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 454, in _read\n",
      "ta618hs3wx-algo-1-xonrr  |     parser = TextFileReader(fp_or_buf, **kwds)\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 948, in __init__\n",
      "ta618hs3wx-algo-1-xonrr  |     self._make_engine(self.engine)\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1180, in _make_engine\n",
      "ta618hs3wx-algo-1-xonrr  |     self._engine = CParserWrapper(self.f, **self.options)\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2010, in __init__\n",
      "ta618hs3wx-algo-1-xonrr  |     self._reader = parsers.TextReader(src, **kwds)\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
      "ta618hs3wx-algo-1-xonrr  |   File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "ta618hs3wx-algo-1-xonrr  | FileNotFoundError: [Errno 2] No such file or directory: '2023-24-UFS14-ML_mene/data/input/housing.csv'\n",
      "ta618hs3wx-algo-1-xonrr  | \n",
      "ta618hs3wx-algo-1-xonrr  | 2023-11-30 21:26:17,675 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmp69995cb0/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmp69995cb0/algo-1-xonrr/output/success -> /tmp/tmp69995cb0/artifacts/output\n",
      "INFO:root:copying /tmp/tmp69995cb0/compressed_artifacts/model.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/output\n",
      "INFO:root:copying /tmp/tmp69995cb0/compressed_artifacts/output.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ta618hs3wx-algo-1-xonrr exited with code 0\n",
      "Aborting on container exit...\n",
      " Container ta618hs3wx-algo-1-xonrr  Stopping\n",
      " Container ta618hs3wx-algo-1-xonrr  Stopped\n",
      "===== Job Complete =====\n",
      "##### ESTIMATOR FIT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "hyperparameters={'epochs': 1}\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='my-custom-sagemaker-training-image',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path='file://{}/data/output'.format(os.getcwd())\n",
    ")\n",
    "\n",
    "print('##### ESTIMATOR FIT STARTED')\n",
    "estimator.fit('file://{}/data/input/housing.csv'.format(os.getcwd()))\n",
    "print('##### ESTIMATOR FIT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4fa234",
   "metadata": {},
   "source": [
    "# NB: if you encountered an error related to `network sagemaker-local was found but has incorrect label com.docker.compose.network set to \"\"` run the following command in the terminal and retry the above cell\n",
    "`docker network prune --force`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3da90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "success\n",
      "Check the above files in the /home/ec2-user/SageMaker/2023-24-UFS14-ML_mene/data/output directory!!!!\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Extracting local training archives to see the results\n",
    "\n",
    "tar -xvf $PWD/data/output/model.tar.gz -C $PWD/data/output/model\n",
    "tar -xvf $PWD/data/output/output.tar.gz -C $PWD/data/output\n",
    "\n",
    "echo \"Check the above files in the $PWD/data/output directory!!!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884de075",
   "metadata": {},
   "source": [
    "# As our image works as expected we can build it again with the right ECR image URI and push it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "788e2947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name: my-custom-sagemaker-training-image ######################\n",
      "account: 778937227063 ######################\n",
      "region: us-east-1 ######################\n",
      "fullname: 778937227063.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-training-image:latest ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  6.249MB\n",
      "Step 1/6 : FROM 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      " ---> 7450831ac673\n",
      "Step 2/6 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 5af1ccf22d77\n",
      "Step 3/6 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> ab934fddfe38\n",
      "Step 4/6 : ADD ./src/train /opt/ml/code/\n",
      " ---> ab7fc7dd3a2c\n",
      "Step 5/6 : ENV SAGEMAKER_PROGRAM my-custom-training-script.py\n",
      " ---> Running in d7761b36b043\n",
      "Removing intermediate container d7761b36b043\n",
      " ---> 31f6cc596f14\n",
      "Step 6/6 : RUN pip install -r /opt/ml/code/requirements.txt\n",
      " ---> Running in bfbce8a16db4\n",
      "Collecting pandas==1.1.5 (from -r /opt/ml/code/requirements.txt (line 1))\n",
      "  Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 75.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker-sklearn-container 2.0 requires pandas==1.1.3, but you have pandas 1.1.5 which is incompatible.\n",
      "\u001b[0mSuccessfully installed pandas-1.1.5\n",
      "Removing intermediate container bfbce8a16db4\n",
      " ---> 524c9f85bffb\n",
      "Successfully built 524c9f85bffb\n",
      "Successfully tagged my-custom-sagemaker-training-image:latest\n",
      "The push refers to repository [778937227063.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-training-image]\n",
      "edc1aaa9d560: Preparing\n",
      "1c690493fbaa: Preparing\n",
      "4c2dcfa9b121: Preparing\n",
      "59f40d769e43: Preparing\n",
      "59aca0976975: Preparing\n",
      "12f19276a761: Preparing\n",
      "fc0d447d4068: Preparing\n",
      "2055ce7cf996: Preparing\n",
      "19c9d750523c: Preparing\n",
      "5ad0c771dfb4: Preparing\n",
      "b286c995ad69: Preparing\n",
      "cbb358ecca6f: Preparing\n",
      "f2ebc9d49f8a: Preparing\n",
      "2143535e12fd: Preparing\n",
      "bfb951982fb4: Preparing\n",
      "85bd37af7361: Preparing\n",
      "a55482fad434: Preparing\n",
      "c4b40f74f67c: Preparing\n",
      "d4601dbe5c9b: Preparing\n",
      "5ef56f1cedab: Preparing\n",
      "1dc52a6b4de8: Preparing\n",
      "f2ebc9d49f8a: Waiting\n",
      "19c9d750523c: Waiting\n",
      "12f19276a761: Waiting\n",
      "5ad0c771dfb4: Waiting\n",
      "2143535e12fd: Waiting\n",
      "bfb951982fb4: Waiting\n",
      "d4601dbe5c9b: Waiting\n",
      "5ef56f1cedab: Waiting\n",
      "85bd37af7361: Waiting\n",
      "1dc52a6b4de8: Waiting\n",
      "fc0d447d4068: Waiting\n",
      "a55482fad434: Waiting\n",
      "c4b40f74f67c: Waiting\n",
      "b286c995ad69: Waiting\n",
      "2055ce7cf996: Waiting\n",
      "cbb358ecca6f: Waiting\n",
      "59aca0976975: Layer already exists\n",
      "4c2dcfa9b121: Layer already exists\n",
      "12f19276a761: Layer already exists\n",
      "59f40d769e43: Layer already exists\n",
      "fc0d447d4068: Layer already exists\n",
      "2055ce7cf996: Layer already exists\n",
      "19c9d750523c: Layer already exists\n",
      "5ad0c771dfb4: Layer already exists\n",
      "cbb358ecca6f: Layer already exists\n",
      "b286c995ad69: Layer already exists\n",
      "f2ebc9d49f8a: Layer already exists\n",
      "2143535e12fd: Layer already exists\n",
      "bfb951982fb4: Layer already exists\n",
      "85bd37af7361: Layer already exists\n",
      "a55482fad434: Layer already exists\n",
      "c4b40f74f67c: Layer already exists\n",
      "d4601dbe5c9b: Layer already exists\n",
      "5ef56f1cedab: Layer already exists\n",
      "1dc52a6b4de8: Layer already exists\n",
      "1c690493fbaa: Pushed\n",
      "edc1aaa9d560: Pushed\n",
      "latest: digest: sha256:dc8aaed80ae63c6f3817312ea6c98ee2f40bb97e09573490db96f3bfbdcd47b3 size: 4719\n",
      "Docker push ended at Thu Nov 30 21:27:14 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-training-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} -f Dockerfile.train .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287217cc",
   "metadata": {},
   "source": [
    "NB: if the last command \"docker push\" remain pending check README.md \"AWS ECR IAM policies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f723b6",
   "metadata": {},
   "source": [
    "Before executing a training job on SageMaker we need to move our input data to AWS S3.\n",
    "Obv. we also need an S3 bucket first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8fb686",
   "metadata": {},
   "source": [
    "# Create an S3 bucket using AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5a477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_S3_BUCKET_NAME=a-random-bucket-name-pino\n"
     ]
    }
   ],
   "source": [
    "# # Generate a random AWS S3 bucket name sharing the name between sh/bash and other Python cells.\n",
    "# # NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "# import random\n",
    "\n",
    "bucket_name='a-random-bucket-name-pino'\n",
    "\n",
    "%set_env AWS_S3_BUCKET_NAME=$bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578ef775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"/a-random-bucket-name-pino\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "aws s3api create-bucket --bucket $AWS_S3_BUCKET_NAME --region $(aws configure get region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7adfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23797/2817417431.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_demo = pd.read_csv(url,',')\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 10)\n",
      "(2064, 10)\n",
      "(2064, 10)\n",
      "mimmo è andato!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "\n",
    "url = 'file://{}/data/input/housing.csv'.format(os.getcwd())\n",
    "df_demo = pd.read_csv(url,',')\n",
    "\n",
    "prefix='demo'\n",
    "train_file='demo_train.csv'\n",
    "test_file='demo_test.csv'\n",
    "validate_file='demo_validate.csv'\n",
    "whole_file='demo.csv'\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "train, test_and_validate = train_test_split(df_demo, \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=42 )\n",
    "\n",
    "test, validate = train_test_split(test_and_validate, \n",
    "                                  test_size=0.5, \n",
    "                                  random_state=42)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket_name).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket_name, prefix, train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket_name, prefix, validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "print('mimmo è andato!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ef821",
   "metadata": {},
   "source": [
    "As we have pushed our Docker image to ECR and uploaded our input data to AWS S3 we can use it with a training job on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "370b63a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### ecr_image is: 778937227063.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-training-image:latest\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: custom-docker-image-for-training-2023-11-30-21-28-21-318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-30 21:28:21 Starting - Starting the training job......\n",
      "2023-11-30 21:28:55 Starting - Preparing the instances for training.........\n",
      "2023-11-30 21:30:39 Downloading - Downloading input data...\n",
      "2023-11-30 21:31:14 Training - Downloading the training image......\n",
      "2023-11-30 21:32:05 Training - Training image download completed. Training in progress....\n",
      "2023-11-30 21:32:52 Uploading - Uploading generated training model\n",
      "2023-11-30 21:32:52 Completed - Training job completed\n",
      "\u001b[34m2023-11-30 21:32:38,020 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2023-11-30 21:32:38,046 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-11-30 21:32:38,047 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas==1.1.5 in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-11-30 21:32:39,129 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"custom-docker-image-for-training-2023-11-30-21-28-21-318\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"my-custom-training-script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"my-custom-training-script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=my-custom-training-script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=my-custom-training-script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"custom-docker-image-for-training-2023-11-30-21-28-21-318\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"my-custom-training-script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python my-custom-training-script.py\u001b[0m\n",
      "\u001b[34mDEBUG:root:Loading the dataset...\u001b[0m\n",
      "\u001b[34mERROR:root:Error occurred: [Errno 2] No such file or directory: '2023-24-UFS14-ML_mene/data/input/housing.csv'\u001b[0m\n",
      "\u001b[34mERROR:root:Traceback (most recent call last):\n",
      "  File \"my-custom-training-script.py\", line 18, in <module>\n",
      "    df = pd.read_csv('2023-24-UFS14-ML_mene/data/input/housing.csv')\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 454, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 948, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1180, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2010, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '2023-24-UFS14-ML_mene/data/input/housing.csv'\u001b[0m\n",
      "\u001b[34m2023-11-30 21:32:40,415 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 133\n",
      "Billable seconds: 133\n",
      "finito kekko!\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "image_name='my-custom-sagemaker-training-image'\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)\n",
    "print('###### ecr_image is: {}'.format(ecr_image))\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=get_execution_role(),\n",
    "    base_job_name='custom-docker-image-for-training',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    output_path='s3://{}'.format(bucket_name)\n",
    ")\n",
    "\n",
    "# start training\n",
    "estimator.fit(inputs=data_channels)\n",
    "print('finito kekko!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c16e8",
   "metadata": {},
   "source": [
    "Before deploy our model we need to test it locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7105371d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [sagemaker-inference internal] load build definition from Dockerfile.inference\n",
      "#1 transferring dockerfile: 644B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [sagemaker-inference internal] load .dockerignore\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [sagemaker-inference internal] load metadata for 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [sagemaker-inference 1/3] FROM 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [sagemaker-inference internal] load build context\n",
      "#5 transferring context: 1.77kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [sagemaker-inference 2/3] ADD ./src/inference /opt/ml/code/\n",
      "#6 CACHED\n",
      "\n",
      "#7 [sagemaker-inference 3/3] RUN pip install -r /opt/ml/code/requirements.txt\n",
      "#7 CACHED\n",
      "\n",
      "#8 [sagemaker-inference] exporting to image\n",
      "#8 exporting layers done\n",
      "#8 writing image sha256:b9b7f2159c44491c74b7c66aea0d357f5eecb08fd0320a1b7816e888f4526995\n",
      "#8 writing image sha256:b9b7f2159c44491c74b7c66aea0d357f5eecb08fd0320a1b7816e888f4526995 done\n",
      "#8 naming to docker.io/library/my-custom-sagemaker-inference-image done\n",
      "#8 DONE 0.0s\n",
      "DOCKER BUILD TERMINATED AT Thu Nov 30 21:33:28 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
    "\n",
    "docker-compose build sagemaker-inference\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc0aac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container sagemaker-inference  Running\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# create our sagemaker-inference container\n",
    "docker-compose create sagemaker-inference\n",
    "\n",
    "# create our sagemaker-inference container\n",
    "docker-compose start sagemaker-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441bc365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Init a Flask app\n",
      "INFO:werkzeug: * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "DEBUG:root:Hello from route /ping\n",
      "INFO:werkzeug:172.22.0.1 - - [30/Nov/2023 21:21:05] \"GET /ping HTTP/1.1\" 200 -\n",
      "DEBUG:root:Hello from route /invocations\n",
      "DEBUG:root:model_files_str\n",
      "DEBUG:root:[\n",
      "    \"/opt/ml/model/my-model-weights.json\"\n",
      "]\n",
      "DEBUG:root:reading file /opt/ml/model/my-model-weights.json\n",
      "DEBUG:root:{\n",
      "    \"no\": [\n",
      "        4\n",
      "    ],\n",
      "    \"yes\": [\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "    ]\n",
      "}\n",
      "DEBUG:root:sys_argv\n",
      "DEBUG:root:[\n",
      "    \"run\",\n",
      "    \"--host\",\n",
      "    \"0.0.0.0\",\n",
      "    \"--port\",\n",
      "    \"8080\"\n",
      "]\n",
      "INFO:werkzeug:172.22.0.1 - - [30/Nov/2023 21:21:05] \"post /invocations HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# read logs of our sagemaker-inference container\n",
    "cat $PWD/data/output-compose/data/logs-inference.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a9615d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /ping BELOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    13  100    13    0     0   4732      0 --:--:-- --:--:-- --:--:--  6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "POST /invocations BELOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    25  100    25    0     0  10141      0 --:--:-- --:--:-- --:--:-- 12500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inference_result\":0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "echo \"GET /ping BELOW\"\n",
    "# call our ping endpoint\n",
    "curl localhost:8080/ping\n",
    "echo \"\"\n",
    "\n",
    "echo \"POST /invocations BELOW\"\n",
    "# call our inference endpoint\n",
    "curl -X post localhost:8080/invocations\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# docker-compose stop sagemaker-inference\n",
    "# docker-compose rm sagemaker-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ed9f9",
   "metadata": {},
   "source": [
    "# Let's go deploy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d306fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-inference-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} -f Dockerfile.inference .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b2cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "aws_region = my_session.region_name\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model_name = 'training-2023-11-23-18-45-31-074'\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': '590460693729.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-inference-image:latest',\n",
    "        'ModelDataUrl': 's3://a-random-bucket-name-751357/custom-docker-image-for-training-2023-11-23-18-45-31-074/output/model.tar.gz',\n",
    "    })\n",
    "\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'my-first-custom-endpoint-config-name'\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'my-first-custom-endpoint'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013bc8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Let's try our inference!!!\n",
    "aws sagemaker-runtime invoke-endpoint --endpoint-name 'my-first-custom-endpoint' --body '{}' inference-response.json\n",
    "\n",
    "cat inference-response.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
